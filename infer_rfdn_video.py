import os
import cv2
import torch
import numpy as np
import time
from RFDN import RFDN  # å¯¼å…¥æ¨¡å‹

# === 1. åŠ è½½æ¨¡å‹ ===
print("ğŸš€ æ­£åœ¨åŠ è½½ RFDN æ¨¡å‹ ...")
model = RFDN()
model_path = 'trained_model/aim_rfdn.pth'
model.load_state_dict(torch.load(model_path, map_location='cpu'))
model.eval()

# === 2. æ‰“å¼€è¾“å…¥è§†é¢‘ ===
video_path = 'input_720p.mp4'
cap = cv2.VideoCapture(video_path)
if not cap.isOpened():
    raise Exception(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘ï¼š{video_path}")

fps = cap.get(cv2.CAP_PROP_FPS)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
print(f"ğŸ¥ è§†é¢‘ä¿¡æ¯: {width}x{height} @ {fps:.0f}fps")

# === 3. åˆ›å»ºè¾“å‡ºè§†é¢‘å†™å…¥å™¨ ===
out_path = 'output_4k.mp4'
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out_writer = cv2.VideoWriter(out_path, fourcc, fps, (width * 4, height * 4))

frame_idx = 0
total_start = time.time()

# === 4. å¸§å¾ªç¯ ===
while True:
    ret, frame = cap.read()
    if not ret:
        break

    start = time.time()

    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    img = frame_rgb.astype(np.float32) / 255.0
    img = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0)

    with torch.no_grad():
        output = model(img).clamp(0, 1).cpu().numpy()

    output_img = np.transpose(output[0], (1, 2, 0)) * 255.0
    output_img = output_img.round().astype(np.uint8)
    output_bgr = cv2.cvtColor(output_img, cv2.COLOR_RGB2BGR)

    out_writer.write(output_bgr)

    end = time.time()
    print(f"âœ… å¸§ {frame_idx} å®Œæˆï¼Œç”¨æ—¶ {end - start:.2f} ç§’")
    frame_idx += 1

# === 5. æ¸…ç†èµ„æº ===
cap.release()
out_writer.release()
total_time = time.time() - total_start
print(f"ğŸï¸ å¤„ç†å®Œæˆï¼Œå…± {frame_idx} å¸§ï¼Œæ€»è€—æ—¶ {total_time:.2f} ç§’")
print(f"ğŸ“ è¾“å‡ºè§†é¢‘è·¯å¾„ï¼š{os.path.abspath(out_path)}")